{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-26885499ba61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m   \u001b[1;31m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m   \u001b[1;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m   \u001b[1;31m# Externally in opensource we must enable exceptions to load the shared object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "#import xlrd\n",
    "import openpyxl\n",
    "import pickle\n",
    "\n",
    "# import torch\n",
    "\n",
    "from joblib import dump,load\n",
    "from sklearn import utils,preprocessing\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso,LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global label\n",
    "# label=\"PRI\"\n",
    "# label=\"FUC\"\n",
    "# label=\"RFE\"\n",
    "label=\"GP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global N\n",
    "global n\n",
    "global test_size     # 回归运行轮次和测试集大小\n",
    "N=100    # runing time for prediction\n",
    "n=10    # runing time for 10K-CV\n",
    "test_size=0.20    # the ratio of testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('list-PRI.xlsx',header=0)    # Primary features\n",
    "# data = pd.read_excel('list-FUC.xlsx',header=0)    # Primary features using statistical functions\n",
    "# data = pd.read_excel('list-RFE.xlsx',header=0)    # Primary features using RFE\n",
    "data = pd.read_excel('list-GP.xlsx',header=0)    # Primary features using Gplearn\n",
    "data = data.iloc[:,1:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(data.iloc[:,1:])    # features\n",
    "y_data = np.array(data.iloc[:,0])    # ΔGH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The number of Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global size\n",
    "size = x_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gerante ANNs model\n",
    "def anns_model(optimizer):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=int(size), input_dim=int(size), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='linear',kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Model regression\n",
    "def fitRegression(inputData,outputData,test_size,N,regr):\n",
    "    r2_train = []    # training R2\n",
    "    r2_test = []    # testing R2\n",
    "    rmse_train = []    # training rmse\n",
    "    rmse_test = []    # testing rmse\n",
    "    mae_train = []\n",
    "    mae_test = []\n",
    "    best_r2 = []\n",
    "    best_rmse = []\n",
    "    for i in range(N):\n",
    "        print('---------round: %d---------'%(i+1))\n",
    "        X_train,X_test,y_train,y_test = train_test_split(inputData,outputData,test_size=test_size,random_state=None)    # Randomly split data                                                                                                                # 该方法对dataframe也适用\n",
    "        score_train = r2_score(y_train,regr.predict(pd.DataFrame(X_train)))\n",
    "        error_train = np.sqrt(sum((y_train-regr.predict(pd.DataFrame(X_train)))**2)/max(y_train.shape))   \n",
    "        mae0_train = sum(abs(y_train-regr.predict(pd.DataFrame(X_train))))/max(y_train.shape)\n",
    "        r2_train.append(score_train)   \n",
    "        rmse_train.append(error_train)\n",
    "        mae_train.append(mae0_train)\n",
    "        print('r2_train:   %.3f'%score_train)\n",
    "        print('RMSE_train: %.3f'%error_train)\n",
    "        print('MAE_train: %.3f'%mae0_train)\n",
    "        \n",
    "        score_test = r2_score(y_test,regr.predict(pd.DataFrame(X_test)))\n",
    "        error_test = np.sqrt(sum((y_test-regr.predict(pd.DataFrame(X_test)))**2)/max(y_test.shape))\n",
    "        mae0_test = sum(abs(y_test-regr.predict(pd.DataFrame(X_test))))/max(y_test.shape)\n",
    "        r2_test.append(score_test)   \n",
    "        rmse_test.append(error_test)\n",
    "        mae_test.append(mae0_test)\n",
    "        print('r2_test:   %.3f'%score_test)\n",
    "        print('RMSE_test: %.3f'%error_test)\n",
    "        print('MAE_test: %.3f'%mae0_test)\n",
    "        if i == 0:\n",
    "            max_score = score_test           #  At run 0, record R2 and the model at this point\n",
    "            worst_mae = mae_test\n",
    "            y_train_best = y_train\n",
    "            y_test_best = y_test\n",
    "            y_train_predict_best = regr.predict(pd.DataFrame(X_train))\n",
    "            y_test_predict_best = regr.predict(pd.DataFrame(X_test))\n",
    "            best_r2 = score_test\n",
    "            best_rmse = error_test\n",
    "        if i>0:\n",
    "            if score_test>max_score:\n",
    "                max_score = score_test       #  Update the maximum R2 value and save the model and the data\n",
    "                y_train_best = y_train\n",
    "                y_test_best = y_test\n",
    "                y_train_predict_best = regr.predict(pd.DataFrame(X_train))\n",
    "                y_test_predict_best = regr.predict(pd.DataFrame(X_test))\n",
    "                best_r2 = score_test\n",
    "                best_rmse = error_test\n",
    "            if mae_test>worst_mae:\n",
    "                worst_mae = mae_test\n",
    "        print('--------------------------') \n",
    "    return r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,worst_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Hyperparameter optimization\n",
    "def optHyperparameter(inputData,outputData,test_size,n,search):\n",
    "    r2 = []\n",
    "    for i in range(n):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(inputData,outputData,test_size=test_size,random_state=None)    \n",
    "        search.fit(X_train,y_train)\n",
    "        regr = search.best_estimator_\n",
    "        r2 = r2_score(y_train,regr.predict(X_train))\n",
    "        if i == 0:\n",
    "            max_score = r2          \n",
    "            best_regr = regr    \n",
    "        if i>0:\n",
    "            if r2>max_score:\n",
    "                max_score = r2       \n",
    "                best_regr = regr  \n",
    "    return max_score,best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  GridCv generation\n",
    "def generateSearch(model,method,param_grid,n_jobs,cv):    \n",
    "    if model=='svr':\n",
    "        svr = SVR()\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(svr,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(svr,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search     \n",
    "    elif model=='krr':\n",
    "        krr = KernelRidge()\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(krr,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(krr,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "    elif model=='rfr':\n",
    "        rfr = RandomForestRegressor()\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(rfr,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(rfr,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "    elif model=='xgbr':\n",
    "        xgbr = XGBRegressor()\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(xgbr,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(xgbr,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "    elif model=='lasso':\n",
    "        lasso = Lasso()\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(lasso,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(lasso,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "    elif model=='anns':\n",
    "        anns = KerasRegressor(anns_model)\n",
    "        if method=='grid_search':\n",
    "            search = GridSearchCV(estimator = anns,param_grid=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search\n",
    "        elif method=='randomized_search':\n",
    "            search = RandomizedSearchCV(estimator = anns,param_distributions=param_grid,n_jobs=n_jobs,cv=cv,scoring = 'r2')\n",
    "            return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Draw bar\n",
    "def plotBar(r2_train,rmse_train,r2_test,rmse_test,N,model,label,saving):\n",
    "    mpl.rcParams['font.sans-serif']=['SimHei'] \n",
    "    mpl.rcParams['axes.unicode_minus']=False \n",
    "    plt.figure(figsize=(6,6))\n",
    "    rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "    mean_rmse_r2 = np.mean(rmse_r2,1) #average\n",
    "    std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) # error bar\n",
    "    error_attri = dict(elinewidth=2, ecolor=\"black\",capsize=3)\n",
    "    x = np.arange(len(rmse_r2))\n",
    "    rects = plt.bar(x,mean_rmse_r2,color=\"c\",width=0.6,align=\"center\",\n",
    "            yerr=std_err,error_kw=error_attri,\n",
    "            tick_label=[\"Training rmse\",\"Testing rmse\",\"Training R2\",\"Testing R2\"])\n",
    "    plt.tick_params(labelsize=8)\n",
    "    for x,mean_rmse_r2,std_err in zip(x,mean_rmse_r2,std_err):\n",
    "        text_str = '%.3f'%mean_rmse_r2+\"±\"+'%.3f'%std_err\n",
    "        plt.text(x,mean_rmse_r2+std_err*1.1,text_str,ha='center',va='bottom',fontsize=10)\n",
    "    plt.ylim([0,1.2])\n",
    "    plt.title(\"Random \"+str(N)+\" times\"+model+\"prediction\",fontsize=10)\n",
    "    if saving == 'saving':\n",
    "        plt.savefig(model+'_plotbar_'+label+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Draw scatter\n",
    "def plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,model,label,saving):\n",
    "    mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "    mpl.rcParams['axes.unicode_minus']=False \n",
    "    R2_train = r2_score(y_train_best,y_train_predict_best)\n",
    "    rmse_train = np.sqrt(sum((y_train_best-y_train_predict_best)**2)/max(y_train_best.shape))\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_train_predict_best,y_train_best,\n",
    "            c='limegreen',\n",
    "            edgecolor='white',\n",
    "            marker='s',\n",
    "            s=50,\n",
    "            alpha=0.9,\n",
    "            label='Training Data')\n",
    "    plt.scatter(y_test_predict_best,y_test_best,\n",
    "            c='steelblue',\n",
    "            edgecolor='white',\n",
    "            marker='o',\n",
    "            s=50,\n",
    "            alpha=0.9,\n",
    "            label='Test Data')\n",
    "# plt.plot(line_x,line_y,linestyle='--',color='black',alpha=0.7)\n",
    "    plt.xlabel(\"Predicted Delta_G\",fontsize=10)\n",
    "    plt.ylabel(\"Actual Delta_G\",fontsize=10)\n",
    "    plt.tick_params(labelsize=10)\n",
    "    plt.legend(loc='upper left',fontsize=10)\n",
    "    plt.title(model+'Training RMSE:%.2f,R2:%.2f Testing RMSE:%.2f,R2:%.2f'%(rmse_train,R2_train,best_rmse,best_r2),fontsize=10)\n",
    "    if saving == 'saving':\n",
    "        plt.savefig(model+'_plotscatter'+label+'.png')\n",
    "    plt.show()\n",
    "    Y_predict = np.concatenate((y_train_predict_best,y_test_predict_best),axis=0)\n",
    "    Y_act = np.concatenate((y_train_best,y_test_best),axis=0)\n",
    "    pd.DataFrame(Y_predict).to_csv('A.csv',sep=',')\n",
    "    pd.DataFrame(Y_act).to_csv('B.csv',sep=',')\n",
    "    Y_total = pd.DataFrame(np.array([Y_predict, Y_act]).T)\n",
    "    Y_total.columns = [\"Predicted GH\", \"Actual GH\"]\n",
    "    Y_total.to_csv(\"Best\\\\\"+model+'_best_prediction_'+label+'.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The beginning of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "time.sleep(5)\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSvrParamGrid(kernel,low1,high1,num1,base1,degree,gamma,low2,high2,num2,base2,epsilon):      # \n",
    "    if isinstance(gamma,int) or isinstance(gamma,float):\n",
    "        param_grid = {\n",
    "            'kernel':kernel,\n",
    "            'C':np.logspace(low1,high1,num1,base=base1),\n",
    "            'degree':degree,\n",
    "            'gamma':np.logspace(low2,high2,num2,base=base2),\n",
    "            'epsilon':epsilon\n",
    "        }\n",
    "        return param_grid\n",
    "    elif isinstance(gamma,list):\n",
    "        param_grid = {\n",
    "            'kernel':kernel,\n",
    "            'C':np.logspace(low1,high1,num1,base=base1),\n",
    "            'degree':degree,\n",
    "            'gamma':gamma,\n",
    "            'epsilon':epsilon\n",
    "        }\n",
    "        return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = generateSvrParamGrid(['linear','poly','rbf'],-3,3,20,2,[3],['scale'],0,0,0,0,[0.001])\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('svr','grid_search',param,-1,10)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,svr_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'SVR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'SVR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr = best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_svr, \"Models\\\\svr_\"+label+\".joblib\")    # Save to hard disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "svr_predicted_result = [mean_rmse_r2,std_err]\n",
    "svr_predicted_result = pd.DataFrame(svr_predicted_result)\n",
    "svr_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "svr_predicted_result.index = [\"Mean\", \"std\"]\n",
    "svr_predicted_result.to_csv(\"Excels\\\\\"+\"SVR_\"+label+\".csv\",sep=',')\n",
    "svr_mae = [mae_train, mae_test]\n",
    "svr_mae = pd.DataFrame(svr_mae)\n",
    "svr_mae.to_csv(\"Excels\\\\\"+\"SVR_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_svr = datetime.datetime.now()\n",
    "delta_svr = end_time_svr - start_time\n",
    "print(end_time_svr)\n",
    "print(delta_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateKrrParamGrid(low1,high1,num1,base1,kernel,low2,high2,num2):      # \n",
    "    param_grid = {\n",
    "        'alpha':np.logspace(low1,high1,num1,base=base1),\n",
    "        'kernel':kernel,\n",
    "        'degree':np.arange(low2,high2,num2)\n",
    "    }\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = generateKrrParamGrid(-6,6,13,10,['linear','poly','rbf'],1,7,0.5)\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('krr','grid_search',param,-1,10)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,krr_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'KRR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'KRR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_krr = best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_krr, \"Models\\\\krr_\"+label+\".joblib\")    # 存储至硬盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "krr_predicted_result = [mean_rmse_r2,std_err]\n",
    "krr_predicted_result = pd.DataFrame(krr_predicted_result)\n",
    "krr_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "krr_predicted_result.index = [\"Mean\", \"std\"]\n",
    "krr_predicted_result.to_csv(\"Excels\\\\\"+\"KRR_\"+label+\".csv\",sep=',')\n",
    "krr_mae = [mae_train, mae_test]\n",
    "krr_mae = pd.DataFrame(krr_mae)\n",
    "krr_mae.to_csv(\"Excels\\\\\"+\"KRR_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_krr = datetime.datetime.now()\n",
    "delta_krr = end_time_krr - end_time_svr\n",
    "print(end_time_krr)\n",
    "print(delta_krr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRfrParamGrid(low1,high1,num1,low2,high2,num2):      # \n",
    "    param_grid = {\n",
    "        'n_estimators':np.arange(int(low1),int(high1),int(num1)),\n",
    "        'max_depth':np.arange(int(low2),int(high2),int(num2))\n",
    "    }\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = generateRfrParamGrid(100,1000,10,1,max(math.floor(x_data.shape[1]/3),1),1)\n",
    "param = generateRfrParamGrid(300,500,10,3,7,1)\n",
    "param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('rfr','grid_search',param,-1,10)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,rfr_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'RFR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'RFR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfr = best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_rfr, \"Models\\\\rfr_\"+label+\".joblib\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "rfr_predicted_result = [mean_rmse_r2,std_err]\n",
    "rfr_predicted_result = pd.DataFrame(rfr_predicted_result)\n",
    "rfr_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "rfr_predicted_result.index = [\"Mean\", \"std\"]\n",
    "rfr_predicted_result.to_csv(\"Excels\\\\\"+\"RFR_\"+label+\".csv\",sep=',')\n",
    "rfr_mae = [mae_train, mae_test]\n",
    "rfr_mae = pd.DataFrame(rfr_mae)\n",
    "rfr_mae.to_csv(\"Excels\\\\\"+\"RFR_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_rfr = datetime.datetime.now()\n",
    "delta_rfr = end_time_rfr - end_time_krr\n",
    "print(end_time_rfr)\n",
    "print(delta_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXgbrParamGrid(low1,high1,num1,low2,high2,num2,low3,high3,num3,rating,bytree,subsample,reg_alpha,reg_lambda,scale_pos_weight,gamma,job):      # \n",
    "    param_grid = {\n",
    "        'n_estimators':np.arange(int(low1),int(high1),int(num1)),\n",
    "        'max_depth':np.arange(int(low2),int(high2),int(num2)),\n",
    "        'min_child_weight':np.arange(int(low3),int(high3),int(num3)),\n",
    "        'learning_rate':[rating],\n",
    "        'colsample_bytree':[bytree],\n",
    "        'subsample':[subsample],\n",
    "        'reg_alpha':[reg_alpha],\n",
    "        'reg_lambda':[reg_lambda],\n",
    "        'scale_pos_weight':[scale_pos_weight],\n",
    "        'gamma':[gamma],\n",
    "        'n_jobs':[job]\n",
    "    }\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = generateXgbrParamGrid(50,100,20, 10,15,1, 5,11,1, 0.2, 1, 0.41000000000000003, 0.2, 0.79, 1, 0, 8)\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('xgbr','grid_search',param,-1,10)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,xgbr_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'XGBR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'XGBR',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgbr = best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_xgbr, \"Models\\\\xgbr_\"+label+\".joblib\")    # 存储至硬盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "xgbr_predicted_result = [mean_rmse_r2,std_err]\n",
    "xgbr_predicted_result = pd.DataFrame(xgbr_predicted_result)\n",
    "xgbr_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "xgbr_predicted_result.index = [\"Mean\", \"std\"]\n",
    "xgbr_predicted_result.to_csv(\"Excels\\\\\"+\"XGBR_\"+label+\".csv\",sep=',')\n",
    "xgbr_mae = [mae_train, mae_test]\n",
    "xgbr_mae = pd.DataFrame(xgbr_mae)\n",
    "xgbr_mae.to_csv(\"Excels\\\\\"+\"XGBR_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_xgbr = datetime.datetime.now()\n",
    "delta_xgbr = end_time_xgbr - end_time_rfr\n",
    "print(end_time_xgbr)\n",
    "print(delta_xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLassoParamGrid(way,low,high,num,base,norm,max_iter):      \n",
    "    if way=='logspace':\n",
    "        param_grid = {\n",
    "            'alpha':np.logspace(low,high,num,base=base),\n",
    "            'normalize':norm,\n",
    "            'max_iter':[int(max_iter)]\n",
    "        }\n",
    "        return param_grid\n",
    "    \n",
    "    elif way=='linspace':\n",
    "        param_grid = {\n",
    "            'alpha':np.linspace(low,high,num),\n",
    "            'normalize':norm,\n",
    "            'max_iter':[int(max_iter)]\n",
    "        }\n",
    "        return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = generateLassoParamGrid('logspace',-4,4,100,10,[True],1000)     \n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('lasso','grid_search',param,-1,10)     \n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,lasso_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'LASSO',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'LASSO',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(best_lasso, \"Models\\\\lasso_\"+label+\".joblib\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "lasso_predicted_result = [mean_rmse_r2,std_err]\n",
    "lasso_predicted_result = pd.DataFrame(lasso_predicted_result)\n",
    "lasso_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "lasso_predicted_result.index = [\"Mean\", \"std\"]\n",
    "lasso_predicted_result.to_csv(\"Excels\\\\\"+\"LASSO_\"+label+\".csv\",sep=',')\n",
    "lasso_mae = [mae_train, mae_test]\n",
    "lasso_mae = pd.DataFrame(lasso_mae)\n",
    "lasso_mae.to_csv(\"Excels\\\\\"+\"LASSO_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_lasso = datetime.datetime.now()\n",
    "delta_lasso = end_time_lasso - end_time_xgbr\n",
    "print(end_time_lasso)\n",
    "print(delta_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras ANNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAnnsParamGrid(low1,high1,num1,low2,high2,num2):      \n",
    "        param_grid = {\n",
    "            'batch_size':np.arange(int(low1),int(high1),int(num1)),\n",
    "            'epochs' :np.arange(int(low2),int(high2),int(num2)),\n",
    "            'optimizer' : ['adam','sgd']\n",
    "        }\n",
    "        return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = generateAnnsParamGrid(10,50,5,100,700,100)  \n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = generateSearch('anns','grid_search',param,-1,10)     \n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score,best_regr = optHyperparameter(x_data,y_data,test_size,n,search)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs = best_regr.sk_params['batch_size']\n",
    "es = best_regr.sk_params['epochs']\n",
    "op = best_regr.sk_params['optimizer']\n",
    "print('最佳batch_size: %s ，最佳epochs: %s，最佳optimizer: %s'%(bs,es,op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train,rmse_train,mae_train,r2_test,rmse_test,mae_test,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,anns_worst_mae= \\\n",
    "fitRegression(x_data,y_data,test_size,N,best_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotBar(r2_train,rmse_train,r2_test,rmse_test,N,'ANNs',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScatter(best_r2,best_rmse,y_train_best,y_train_predict_best,y_test_best,y_test_predict_best,'ANNs',label,'saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regr.model.save(\"Models\\\\anns_\"+label+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_r2 = [rmse_train, rmse_test, r2_train, r2_test]\n",
    "mean_rmse_r2 = np.mean(rmse_r2,1) \n",
    "std_err = np.std(rmse_r2,axis=1,ddof=1)/np.sqrt(N) \n",
    "anns_predicted_result = [mean_rmse_r2,std_err]\n",
    "anns_predicted_result = pd.DataFrame(anns_predicted_result)\n",
    "anns_predicted_result.columns = [\"Training rmse\", \"Testing rmse\", \"Training R2\", \"Testing R2\"]\n",
    "anns_predicted_result.index = [\"Mean\", \"std\"]\n",
    "anns_predicted_result.to_csv(\"Time\\\\\"+\"ANNS_\"+label+\".csv\",sep=',')\n",
    "anns_mae = [mae_train, mae_test]\n",
    "anns_mae = pd.DataFrame(anns_mae)\n",
    "anns_mae.to_csv(\"Excels\\\\\"+\"ANNS_MAE.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_anns = datetime.datetime.now()\n",
    "delta_anns = end_time_anns - end_time_lasso\n",
    "print(end_time_anns)\n",
    "print(delta_anns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ending of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_comp = [delta_svr,delta_krr,delta_rfr,delta_xgbr,delta_lasso,delta_anns]\n",
    "time_comp = pd.DataFrame(time_comp)\n",
    "time_comp.columns=['time cost']\n",
    "time_comp.index = ['SVR','KRR','RFR','XGBR','LASSO','ANNs']\n",
    "time_comp.to_csv(\"Time\\\\\"+\"Time_\"+label+\".csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The worst MAE in a trial for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_mae = [svr_worst_mae,krr_worst_mae,rfr_worst_mae,xgbrt_worst_mae,lasso_worst_mae,anns_worst_mae] \n",
    "worst_mae = pd.DataFrame(worst_mae)\n",
    "worst_mae.columns=['mae']\n",
    "worst_mae.index = ['SVR','KRR','RFR','XGBR','LASSO','ANNs']\n",
    "worst_mae.to_csv(\"Worst\\\\\"+\"worstMAE_\"+label+\".csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del N,n,label,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
